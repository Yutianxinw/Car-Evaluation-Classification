{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe022bd2-986f-48be-ae30-9169bd4aa02c",
   "metadata": {},
   "source": [
    "This file shows the model building process using nested CV to find the best model that fit with the car evulation dataset,\n",
    "I tested multiple learning techniques including decision tree, KNN, Naive Bayes, SVM and Logistic regression\n",
    "Processing steps: \n",
    "1. Data encoding / ordinal data trans as a categorical data\n",
    "2. Normalized the data\n",
    "3. Doing nested CV for each model and pick the best performance model on the dataset\n",
    "4. Grind Search for tuning the model with best hyperparameter\n",
    "5. Apply the model on the testing set to evulate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16cfa68-548f-48ac-991e-595594f36df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a85524bd-f165-4a01-908f-39c2e4924682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "unacc    1210\n",
       "acc       384\n",
       "good       69\n",
       "vgood      65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
    "columns = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "df = pd.read_csv(url, names=columns)\n",
    "\n",
    "df.head()\n",
    "# Display the first few rows and class distribution\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4ceea-5144-4734-ae8f-c42db2e16407",
   "metadata": {},
   "source": [
    "#### Data Encoding as Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6753bebe-e215-4d34-9bcc-93f5fff34ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety  class\n",
       "0     3.0    3.0    0.0      0.0       2.0     1.0    2.0\n",
       "1     3.0    3.0    0.0      0.0       2.0     2.0    2.0\n",
       "2     3.0    3.0    0.0      0.0       2.0     0.0    2.0\n",
       "3     3.0    3.0    0.0      0.0       1.0     1.0    2.0\n",
       "4     3.0    3.0    0.0      0.0       1.0     2.0    2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code as a numeric\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "df = pd.DataFrame(encoder.fit_transform(df), columns=df.columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81eff2b1-4722-4349-8bc7-05249a69f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into features and target variable\n",
    "X = df.drop(\"class\", axis=1) # features\n",
    "y = df[\"class\"] # target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "886f7196-fcdf-4b52-91b3-4501cf373f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Class Distribution after SMOTE on Training Data:\n",
      " class\n",
      "3.0    852\n",
      "2.0    852\n",
      "0.0    852\n",
      "1.0    852\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE only to the training data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check Balanced Class Distribution in Training Data\n",
    "balanced_classes = pd.Series(y_train).value_counts()\n",
    "print(\"Balanced Class Distribution after SMOTE on Training Data:\\n\", balanced_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4ccb250-dde1-4307-b421-7f956459a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca9f15d-605c-4ada-969a-2a6904348565",
   "metadata": {},
   "source": [
    "1. Decision Tree Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11032383-5a82-43e2-9e0e-75865ebd9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e70c0497-40bc-4988-b194-17c0ee4e6ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Nested CV Score: 0.9870153094604615\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Model with Nested Cross-Validation\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "nested_scores = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(X_train_scaled, y_train):\n",
    "    X_train_outer, X_test_outer = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_outer, y_test_outer = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid_search_dt = GridSearchCV(tree.DecisionTreeClassifier(random_state=42), param_grid_dt, cv=inner_cv, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_dt.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    best_model = grid_search_dt.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test_outer)\n",
    "    nested_scores.append(grid_search_dt.best_score_)\n",
    "    #print(classification_report(y_test_outer, y_pred))\n",
    "\n",
    "print(\"Average Nested CV Score:\", sum(nested_scores)/len(nested_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7423ac8c-1895-40e1-b31b-33a43cce6587",
   "metadata": {},
   "source": [
    "2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "676d52e0-891c-42ef-943c-039b789c04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5383bf8d-a074-4221-8fac-43a00b8b6d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Nested CV Score: 0.9487956137757682\n"
     ]
    }
   ],
   "source": [
    "# K-NN Model with Nested Cross-Validation\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # Manhattan and Euclidean distances\n",
    "}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "nested_scores = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(X_train_scaled, y_train):\n",
    "    X_train_outer, X_test_outer = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_outer, y_test_outer = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=inner_cv, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_knn.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    best_model = grid_search_knn.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_outer)\n",
    "    nested_scores.append(grid_search_knn.best_score_)\n",
    "    # print(classification_report(y_test_outer, y_pred))\n",
    "\n",
    "print(\"Average Nested CV Score:\", np.mean(nested_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2c277-158c-4fca-916a-15774717d4b1",
   "metadata": {},
   "source": [
    "3. Naive Beyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b70694c-00a1-4daa-b7cb-c7d6f8f5b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f311a8a-551f-4e91-ac97-668a85fb259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Nested CV Score: 0.6015244099370858\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Model with Nested Cross-Validation\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "nested_scores = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(X_train_scaled, y_train):\n",
    "    X_train_outer, X_test_outer = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_outer, y_test_outer = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    y_pred = nb_model.predict(X_test_outer)\n",
    "    nested_scores.append(nb_model.score(X_test_outer, y_test_outer))\n",
    "\n",
    "print(\"Average Nested CV Score:\", np.mean(nested_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feef18c-b641-49fb-8713-466904219089",
   "metadata": {},
   "source": [
    "4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff543822-7088-46dc-afda-3dc96205922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72d88603-3409-47f6-904f-d33da73653d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Nested CV Score: 0.5779777684082652\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with Nested Cross-Validation\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "nested_scores = []\n",
    "for train_idx, test_idx in outer_cv.split(X_train_scaled, y_train):\n",
    "    X_train_outer, X_test_outer = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_outer, y_test_outer = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid_search_lr = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_lr, cv=inner_cv, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_lr.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    best_model = grid_search_lr.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_outer)\n",
    "    nested_scores.append(grid_search_lr.best_score_)\n",
    "    \n",
    "print(\"Average Nested CV Score:\", np.mean(nested_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7de20-8ce6-42b2-ab53-fc9560f96a3b",
   "metadata": {},
   "source": [
    "5. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e5fd6fe-1247-4084-b960-2eb20a2b95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba7271b0-be92-46c4-a93b-25313dab7699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Nested CV Score: 0.9976525821596244\n"
     ]
    }
   ],
   "source": [
    "# SVM Model with Nested Cross-Validation\n",
    "param_grid_svm = {\n",
    "    'C': [0.1,1,10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "nested_scores = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(X_train_scaled, y_train):\n",
    "    X_train_outer, X_test_outer = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_outer, y_test_outer = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid_search_svm = GridSearchCV(SVC(), param_grid_svm, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_model = grid_search_svm.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_outer)\n",
    "    nested_scores.append(grid_search_svm.best_score_)\n",
    "\n",
    "print(\"Average Nested CV Score:\", np.mean(nested_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd848c-1589-4882-9bb4-31fd47bdead1",
   "metadata": {},
   "source": [
    "##### After doing the nested CV based on the training dataset, the SVM classification has the best performance on the average nested CV score. Further, I'll run the grid search corss validation again to find the best hyper parameter and testing the model use the testing dataset to evulate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2a2f9502-03c1-447d-a8dc-bfd04fdbe950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 0.01],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(SVC(), param_grid_svm, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display best parameters and results\n",
    "print(\"Best Parameters:\", grid_search_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "34316742-5291-4be2-b512-414626e06563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Performance on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97       356\n",
      "         1.0       0.98      1.00      0.99       347\n",
      "         2.0       1.00      0.95      0.98       385\n",
      "         3.0       1.00      1.00      1.00       364\n",
      "\n",
      "    accuracy                           0.98      1452\n",
      "   macro avg       0.98      0.98      0.98      1452\n",
      "weighted avg       0.98      0.98      0.98      1452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model with best parameters\n",
    "final_model = SVC(C=1, gamma='scale', kernel='rbf')\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_pred_test = final_model.predict(X_test_scaled)\n",
    "print(\"SVM Model Performance on Test Data:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5b3fe-6db8-4f16-bcaa-2d7008be11cb",
   "metadata": {},
   "source": [
    "##### The final SVM model achieved on overall accuracy of 98%, illustrating its good preditive capability. It perform well between class 0 2 and 3. The class 1 has a lower precision for class 1 suggests a potential overfitting compare to other classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17878234-31fb-418a-bb7c-b49e791795d2",
   "metadata": {},
   "source": [
    "##### Now i started to do the categorical encoding version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd3a788a-aac8-4de1-afbf-758f0eef47df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>buying_0.0</th>\n",
       "      <th>buying_1.0</th>\n",
       "      <th>buying_2.0</th>\n",
       "      <th>buying_3.0</th>\n",
       "      <th>maint_0.0</th>\n",
       "      <th>maint_1.0</th>\n",
       "      <th>maint_2.0</th>\n",
       "      <th>maint_3.0</th>\n",
       "      <th>doors_0.0</th>\n",
       "      <th>...</th>\n",
       "      <th>doors_3.0</th>\n",
       "      <th>persons_0.0</th>\n",
       "      <th>persons_1.0</th>\n",
       "      <th>persons_2.0</th>\n",
       "      <th>lug_boot_0.0</th>\n",
       "      <th>lug_boot_1.0</th>\n",
       "      <th>lug_boot_2.0</th>\n",
       "      <th>safety_0.0</th>\n",
       "      <th>safety_1.0</th>\n",
       "      <th>safety_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  buying_0.0  buying_1.0  buying_2.0  buying_3.0  maint_0.0  \\\n",
       "0      2           0           0           0           1          0   \n",
       "1      2           0           0           0           1          0   \n",
       "2      2           0           0           0           1          0   \n",
       "3      2           0           0           0           1          0   \n",
       "4      2           0           0           0           1          0   \n",
       "\n",
       "   maint_1.0  maint_2.0  maint_3.0  doors_0.0  ...  doors_3.0  persons_0.0  \\\n",
       "0          0          0          1          1  ...          0            1   \n",
       "1          0          0          1          1  ...          0            1   \n",
       "2          0          0          1          1  ...          0            1   \n",
       "3          0          0          1          1  ...          0            1   \n",
       "4          0          0          1          1  ...          0            1   \n",
       "\n",
       "   persons_1.0  persons_2.0  lug_boot_0.0  lug_boot_1.0  lug_boot_2.0  \\\n",
       "0            0            0             0             0             1   \n",
       "1            0            0             0             0             1   \n",
       "2            0            0             0             0             1   \n",
       "3            0            0             0             1             0   \n",
       "4            0            0             0             1             0   \n",
       "\n",
       "   safety_0.0  safety_1.0  safety_2.0  \n",
       "0           0           1           0  \n",
       "1           0           0           1  \n",
       "2           1           0           0  \n",
       "3           0           1           0  \n",
       "4           0           0           1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Apply one-hot encoding to the entire dataset (except the target variable) and convert booleans to integers\n",
    "car_encoded_df = pd.get_dummies(df, columns=df.columns[:-1]).astype(int)\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Label encode the target variable\n",
    "car_encoded_df['class'] = le.fit_transform(df['class'])\n",
    "\n",
    "# Display the first few rows of the encoded dataset\n",
    "car_encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9787dc20-8e2c-4df2-a2bd-890e43a20dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Class Distribution After Random Over-Sampling:\n",
      " class\n",
      "2    847\n",
      "0    847\n",
      "1    847\n",
      "3    847\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Step 1: Prepare Features and Target\n",
    "X = car_encoded_df.drop(columns=['class']).reset_index(drop=True)  # Reset index before splitting\n",
    "y = car_encoded_df['class'].reset_index(drop=True)\n",
    "\n",
    "# Step 2: Train-Test Split BEFORE applying Over-Sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Step 3: Apply Random Over-Sampling only to Training Data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 4: Convert Resampled Data Back to DataFrame\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)  # Restore column names\n",
    "y_train= pd.Series(y_train, name='class')  # Restore target as a Pandas Series\n",
    "\n",
    "# Step 5: Check Class Balance\n",
    "balanced_classes = y_train.value_counts()\n",
    "print(\"Balanced Class Distribution After Random Over-Sampling:\\n\", balanced_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6065f43-0c5d-406e-88ed-92f83f039f9a",
   "metadata": {},
   "source": [
    "1. Descision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea717b96-9aa1-4956-8fbe-1487120bad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Nested CV Score: 0.9946854725210563\n"
     ]
    }
   ],
   "source": [
    "# Define Hyperparameter Grid\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Outer CV for model evaluation\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "nested_scores = []\n",
    "\n",
    "# Nested Cross-Validation Loop\n",
    "for train_idx, test_idx in outer_cv.split(X_train, y_train):\n",
    "    # Ensure proper indexing (assuming X_train is a DataFrame and y_train is a Series)\n",
    "    X_train_outer, X_test_outer = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_outer, y_test_outer = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Inner CV for hyperparameter tuning\n",
    "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid_search_dt = GridSearchCV(tree.DecisionTreeClassifier(random_state=42),param_grid_dt,cv=inner_cv,scoring='accuracy',n_jobs=-1)\n",
    "    grid_search_dt.fit(X_train_outer, y_train_outer)\n",
    "    \n",
    "    best_model = grid_search_dt.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_outer)\n",
    "    outer_accuracy = accuracy_score(y_test_outer, y_pred)\n",
    "    nested_scores.append(outer_accuracy)\n",
    "\n",
    "# Final Nested Cross-Validation Score\n",
    "print(\"Average Nested CV Score:\", sum(nested_scores) / len(nested_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffe65a-877c-48d1-8430-6262c01daeea",
   "metadata": {},
   "source": [
    "2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47467da4-c555-4e52-b728-6cd8bcd91847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "307aeefc-0e45-487d-bc72-4d06fd6a1dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Nested CV Score: 0.9726991640451199\n"
     ]
    }
   ],
   "source": [
    "# K-NN Model with Nested Cross-Validation\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # Manhattan and Euclidean distances\n",
    "}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "nested_scores = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(X_train, y_train):\n",
    "    X_train_outer, X_test_outer = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_outer, y_test_outer = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=inner_cv, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_knn.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    best_model = grid_search_knn.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_outer)\n",
    "    nested_scores.append(grid_search_knn.best_score_)\n",
    "    # print(classification_report(y_test_outer, y_pred))\n",
    "\n",
    "print(\"Average Nested CV Score:\", np.mean(nested_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3327d-d11e-49f4-b1fd-c5a414bda445",
   "metadata": {},
   "source": [
    "3. Naive Beyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "488daf03-ffcf-46ce-993c-b7b6a3a57e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Nested CV Score: 0.8645220323917334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# Outer and inner cross-validation\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "nested_scores = []\n",
    "best_models = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(X_train, y_train):\n",
    "    X_train_outer, X_test_outer = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_outer, y_test_outer = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Naive Bayes does not have hyperparameters to tune extensively, so we fit directly\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    best_models.append(nb_model)\n",
    "    y_pred = nb_model.predict(X_test_outer)\n",
    "    nested_scores.append(accuracy_score(y_test_outer, y_pred))\n",
    "\n",
    "print(\"Average Nested CV Score:\", np.mean(nested_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d65e4-8b24-4e1f-b718-3e32b2631140",
   "metadata": {},
   "source": [
    "4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f03dc119-7fdc-4d27-91f1-386804e0cc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Nested CV Score: 0.8645220323917334\n"
     ]
    }
   ],
   "source": [
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Outer and inner cross-validation\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "nested_scores = []\n",
    "best_models = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(X_train, y_train):\n",
    "    X_train_outer, X_test_outer = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_outer, y_test_outer = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Grid search for hyperparameter tuning\n",
    "    grid_search_svm = GridSearchCV(SVC(), param_grid_svm, cv=inner_cv, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_svm.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    best_models.append(nb_model)\n",
    "    y_pred = nb_model.predict(X_test_outer)\n",
    "    nested_scores.append(accuracy_score(y_test_outer, y_pred))\n",
    "\n",
    "print(\"Average Nested CV Score:\", np.mean(nested_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba887e1-f35a-40e0-8ba8-2f3ec790ef9e",
   "metadata": {},
   "source": [
    "5. Logistic Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b65ea44-cec4-485f-88f2-a652221c6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Nested CV Score: 0.9650979037426867\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with Nested Cross-Validation\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "nested_scores = []\n",
    "for train_idx, test_idx in outer_cv.split(X_train, y_train):\n",
    "    X_train_outer, X_test_outer = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_outer, y_test_outer = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid_search_lr = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_lr, cv=inner_cv, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_lr.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    best_model = grid_search_lr.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_outer)\n",
    "    nested_scores.append(grid_search_lr.best_score_)\n",
    "    \n",
    "print(\"Average Nested CV Score:\", np.mean(nested_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573387f0-b186-4caf-92b9-a6926c43a33e",
   "metadata": {},
   "source": [
    "##### Desision tree has the best Nested CV score, so the following section shows the decision tree grid search with testing dataset performance on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00d27b87-fc8e-467d-87b8-13829138c7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Decision Tree: {'criterion': 'entropy', 'max_depth': 10}\n",
      "Test Set Accuracy for Decision Tree: 0.9730250481695568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       115\n",
      "           1       0.72      1.00      0.84        21\n",
      "           2       1.00      0.98      0.99       363\n",
      "           3       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           0.97       519\n",
      "   macro avg       0.92      0.98      0.94       519\n",
      "weighted avg       0.98      0.97      0.97       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(tree.DecisionTreeClassifier(random_state=42), param_grid_dt, cv=5, scoring='accuracy')\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best parameters and the best model\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "best_model_dt = grid_search_dt.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test_dt = best_model_dt.predict(X_test)\n",
    "final_accuracy_dt = accuracy_score(y_test, y_pred_test_dt)\n",
    "\n",
    "print(\"Best Parameters for Decision Tree:\", best_params_dt)\n",
    "print(\"Test Set Accuracy for Decision Tree:\", final_accuracy_dt)\n",
    "print(classification_report(y_test, y_pred_test_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf2584-30a1-4deb-8210-c768e3580088",
   "metadata": {},
   "source": [
    "#### Comparing with numerical and categorical data, SVM with numerical encoding stands out as the best performer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce490a-dd61-44e2-870c-d8bfadf69662",
   "metadata": {},
   "source": [
    "#### Treating Ordinal Variables as Numeric / Map ordinal categories to integers and use directly in the model.\n",
    "Pros:\n",
    "Preserves Order: Models can leverage the ordinal relationships (e.g., \"high\" > \"medium\" > \"low\").\n",
    "Simplifies Data: Reduces dimensionality,  leading to faster training and less memory usage.\n",
    "Works Well with Distance-Based Models: Algorithms like SVM and K-NN that rely on distance metrics\n",
    "Cons:\n",
    "Assumes Uniform Distance: Implies equal spacing between categories, which may not reflect reality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f8fd3e-cf46-4795-aded-998b3041d3d4",
   "metadata": {},
   "source": [
    "#### Treating Ordinal Variables as Categorical (One-Hot Encoding) / Approach: Convert each ordinal variable into binary dummy variables, representing the presence/absence of each category.\n",
    "Pros:\n",
    "No Assumed Order or Distance: Models are free from potentially misleading numeric assumptions.\n",
    "Better for Tree-Based Models: Decision Trees and Random Forests can split on individual binary features, leading to clearer decision boundaries.\n",
    "Cons:\n",
    "Loss of Ordinal Information: The natural order between categories is not preserved.\n",
    "Increased Dimensionality: One-hot encoding can slow down training and increase the risk of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ac20f-0bd1-4c18-83b1-28a80376f5b4",
   "metadata": {},
   "source": [
    "#### The SVM with numeric encoding outperformed the Decision Tree with categorcial encoding, achieving higher accuracy and more balanced class-wise performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
